<html>
  <head>
     <title>Bayes Inference</title>
     <link rel="stylesheet" media="screen" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css">
     <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap-theme.min.css">
     <meta name="viewport" content="width=device-width, initial-scale=1.0">

  </head>
  <body>

    <div class="container"><br>
      <center>
        <h2>Bayes Inference</h2>
      </center>
    </div>

    <div class=container"><br>
        <div class="row align-items-center justify-content-center">
            <div class="col-md-4">
                <form  action="" method="post" role="form">
                    {{ form.csrf }}
                    <div class="form-group">

                        <label for="specificity">Specificity:</label>
                        <input type="text" class="form-control" id="name" name="specificity" placeholder="Specificity Value">
                            <br>
                        <label for="sensitivity">Sensitivity:</label>
                        <input type="text" class="form-control" id="sensitivity" name="sensitivity" placeholder="Sensitivity Value">
                        <br>
                        <label for="prevalence">Prevalence:</label>
                        <input type="text" class="form-control" id="prevalence" name="prevalence" placeholder="Population Prevalence">
                            <br>
                        <label for="threshold">Threshold:</label>
                        <input type="text" class="form-control" id="threshold" name="threshold" placeholder="Probability Threshold">

                    </div>
                    <br>													   

                    <center>
                    <button type="submit" class="btn btn-success">Bayes Inference</button>
                    </center>
                </form>

                <br>

                {% with messages = get_flashed_messages(with_categories=true) %}
                    {% if messages %}

                {% for message in messages %}
                    {% if "Error" not in message[1]: %}
                        <div class="alert alert-info">
                        <strong>Success! </strong> {{ message[1] }}
                        </div>
                        
                    {% endif %}

                    {% if "Error" in message[1]: %}
                        <div class="alert alert-danger">
                        <strong>Error: </strong> {{ message[1] }}
                        </div>
                    {% endif %}
                {% endfor %}
                    {% endif %}
                {% endwith %}

            </div>
            <br>
        </div>
    </div>
    {% if value != None %}
        <div style="margin-left: 50px;">
            <h2>Bayes Inference Results.</h2>
            <br>
            <p>The probability of finding true positive from the test is: {{ value }}</p>
            {% if value < threshold %}
                <p>The test is <strong>not as reliable</strong> <i>since its probability of a true positive, {{ value }}, is less than its probability threshold {{ threshold }}</i> .</p>
                <br>
                <p>Let’s see how the probability changes with the prevalence rate.</p>
                <script src="https://cdn.plot.ly/plotly-latest.min.js"></script>
                <script src="https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.6/d3.min.js"></script>
                <div class="chart" id="bargraph">
                    <script>
                        var graphs = {{plot | safe}};
                        Plotly.plot('bargraph',graphs,{});
                    </script>
                </div>
                <p>Your decision depends on the probability threshold. Currently it is set to 
                    <strong>{{threshold}}</strong>. You can lower it if necessary. But, at the threshold of <strong>{{threshold}}</strong>,
                     you need to have the prevalence % rate of the value at the extreme top right direction of the line curve.
                </p>
                <br>
                <h3>How can the scenario be improved?</h3>
                <br>
                <!-- pick up from here -->
                <p>For Bayes Inference computation, the test's sensitivity and specificity strongly influence the computation. Let's look at
                     what is needed to improve the probability of catching a true positive.
                </p>
                <div class="chart" id="linegraph">
                    <script>
                        var graphs = {{sens | safe}};
                        Plotly.plot('linegraph',graphs,{});
                    </script>
                </div>
                <p>The plot above shows how much we gain with a sensitivity close to 100%. This significance of the gain can be determined by
                     checking the difference between the probability at 100% sensitivity and the probability got from the Bayes Inference above. <i>Also, the <strong>non-linearity</strong> of
                      the probabilty response with respect to sensitivity is a sign of significance with increased sensitivity.</i>
                     If the difference is significant improvement or the graph is non-linear, then you should consider efforts to tweak the <strong>sensitivity of the test</strong>
                      towards that value, say 100%.
                </p>
                <p>If there is nothing significant from the sensitivity plot above you might want to look at the <strong>specificity plot</strong> below.</p>
                <div class="chart" id="specgraph">
                    <script>
                        var graphs = {{specs | safe}};
                        Plotly.plot('specgraph',graphs,{});
                    </script>
                </div>
                <p>
                    Check the probability response with respect to specificity of the test. A highly non-linear graph as it reaches perfection indicate a large increase
                    in the probability of catching a true positive. This would mean efforts should be focused on how to improve the <strong>specificity of the test</strong>.
                </p>
                <p>
                    Intuitively, the above conclusion is with low population prevalence rate the focus should be
                    on catching true negatives correctly (improve specificity) since they are a much larger number than true positives. The opposite holds.
                </p>

                <h3>Chain Bayes' Rule</h3>
                <br>
                <p>
                    In Bayesian Inference there is the ability to use <strong>prior knowledge</strong> in the form of <i>prior probability term</i> in the numerator of the Bayes'
                    theorem.
                    <br>
                    The prior knowledge is the <i>computed probability of the test</i> which is then fed back to the next test. That is, in case of an extremely low population prevalence
                    , one can increase confidence by conducting a second test if the first test result is positive. The posterior probability from the first test becomes the prior for the 
                    second test. The probability of a true positive is not the general prevalence rate for the second test, but the probability from the first test: <strong>{{ value }}</strong>.
                </p>
                <br>
                <p><strong><i>Chaining the bayes inference gives the results: </i></strong></p>
                <ul>
                    <li>The probability of catching a true positive in the first test is: <strong>{{ value }}</strong></li>
                    <li>The probability of catching a true positive in the second round of the test is: <strong>{{ probTwo }}</strong></li>
                    <li>The probability of catching a true positive in the third round of the test is: <strong>{{ probThree }}</strong></li>
                </ul>
                <p>You can see with chaining there is improvement the probability responses. Therefore, for a test that is not as reliable the first time, reuse it multiple times to improve confidence
                    with successive application of Bayes' Theorem, also chaining.
                </p>

            {% elif value > threshold %}
            <p>The test is <strong>reliable</strong> <i>since its probability of a true positive, {{ value }}, is more than its probability threshold {{ threshold }}</i> .</p>
            <br>
            <p>Let’s see how the probability changes with the prevalence rate.</p>
            <script src="https://cdn.plot.ly/plotly-latest.min.js"></script>
            <script src="https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.6/d3.min.js"></script>
            <div class="chart" id="bargraph">
                <script>
                    var graphs = {{plot | safe}};
                    Plotly.plot('bargraph',graphs,{});
                </script>
            </div>
            <p>Your decision depends on the probability threshold. Currently it is set to 
                <strong>{{threshold}}</strong>. You can lower or increase it if necessary. But currently the test beats the set threshold of <strong>{{threshold}}</strong>.
            </p>
            <br>
            <h3>Any improvements?</h3>
            <br>
            <!-- pick up from here -->
            <p>For Bayes Inference computation, the test's sensitivity and specificity strongly influence the computation. Let's look at
                 what is needed to improve the probability of catching a true positive.
            </p>
            <div class="chart" id="linegraph">
                <script>
                    var graphs = {{sens | safe}};
                    Plotly.plot('linegraph',graphs,{});
                </script>
            </div>
            <p>The plot above shows how much we gain with a sensitivity close to 100%. This significance of the gain can be determined by
                 checking the difference between the probability at 100% sensitivity and the probability got from the Bayes Inference above. <i>Also, the <strong>non-linearity</strong> of
                  the probabilty response with respect to sensitivity is a sign of significance with increased sensitivity.</i>
                 If the difference is significant improvement or the graph is non-linear, then you should consider efforts to tweak the <strong>sensitivity of the test</strong>
                  towards that value, say 100%.
            </p>
            <p>If there is nothing significant from the sensitivity plot above you might want to look at the <strong>specificity plot</strong> below.</p>
            <div class="chart" id="specgraph">
                <script>
                    var graphs = {{specs | safe}};
                    Plotly.plot('specgraph',graphs,{});
                </script>
            </div>
            <p>
                Check the probability response with respect to specificity of the test. A highly non-linear graph as it reaches perfection indicate a large increase
                in the probability of catching a true positive. This would mean efforts should be focused on how to improve the <strong>specificity of the test</strong>.
            </p>
            <p>
                Intuitively, the above conclusion is with low population prevalence rate the focus should be
                on catching true negatives correctly (improve specificity) since they are a much larger number than true positives. The opposite holds.
            </p>

            <h3>Chain Bayes' Rule</h3>
            <br>
            <p>
                In Bayesian Inference there is the ability to use <strong>prior knowledge</strong> in the form of <i>prior probability term</i> in the numerator of the Bayes'
                theorem.
                <br>
                The prior knowledge is the <i>computed probability of the test</i> which is then fed back to the next test. That is, in case of an extremely low population prevalence
                , one can increase confidence by conducting a second test if the first test result is positive. The posterior probability from the first test becomes the prior for the 
                second test. The probability of a true positive is not the general prevalence rate for the second test, but the probability from the first test: <strong>{{ value }}</strong>.
            </p>
            <br>
            <p><strong><i>Chaining the bayes inference gives the results: </i></strong></p>
            <ul>
                <li>The probability of catching a true positive in the first test is: <strong>{{ value }}</strong></li>
                <li>The probability of catching a true positive in the second round of the test is: <strong>{{ probTwo }}</strong></li>
                <li>The probability of catching a true positive in the third round of the test is: <strong>{{ probThree }}</strong></li>
            </ul>
            <p>You can see with chaining there is improvement the probability responses. Therefore, for a test that is not as reliable the first time, reuse it multiple times to improve confidence
                with successive application of Bayes' Theorem, also chaining.
            </p>
                
            {% endif %}
        </div>
    {% endif %}
    
  </body>
</html>